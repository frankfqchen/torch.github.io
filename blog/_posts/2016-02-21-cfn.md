---
layout: post
title: Collaborative Filtering with Neural Networks
comments: True
author: florian-strub
excerpt: Collaborative Filtering methods are a key algorithm for Recommender Systems. They are used by major companies such as Netflix, Amazon or Spotify to suggest items to users.  While Neural Networks have tremendous success in image and speech recognition, Collaborative Filtering received less attention as it deals with sparse inputs/targets. After a quick introduction to Recommendation Systems, we show how to implement Autoencoders to perform Collaborative Filtering.
picture: http://insidebigdata.com/wp-content/uploads/2014/06/Humor_recommender.jpg
---

<!---# Recurrent Model of Visual Attention-->

Deep Learning has well-known state-of-the arts results in Computer Vision, Speech Recognition or Natural Language Processing.
This post aims at using Neural Networks on a different topic : Recommender systems and Collaborative Filtering. 
It turns out that Neural Networks also perform among the best Collaborative Fitering algorithms. 

#Introduction#

Recommendation systems are a subclass of algorithms that seek to predict the rating that a user would give to an item.
A good recommendation system may dramatically increase the amount of sales of a firm or retain customers. For instance, 80% of movies watched on Netflix come from the recommender system of the company

One of the most successful approach of Recommendation systems is to use the explicit feedback of users to build a Matrix of ratings. This technique is known as Collaborative Filtering.

For instance, if we gather the feedback of all users into a matrix, we obtain a sparse matrix of ratings. Note that sparsity is induced by unknown values.

![ratings](http://florian-strub.com/tmp/initialMatrix.png)

In this case, should we recommend Bob to watch _The Exorcist_ or _Titanic_?

Collaborative Filtering aims at estimating the ratings a user would have given to other movies by using the ratings of all the other users.
Inherent features of users or items such as the genre, age, actors or some descriptions are _not_ take into account. 
The goal is then to turn the previous sparse matrix of ratings into a dense one:

![ratings](http://florian-strub.com/tmp/finalMatrix.png)

Therefore, the Recommender System will advise Bob to watch _The Exorcist_. 

If Bob eventually rates _The Exorcist_, the matrix is re-estimated and so on... 
In practice, the matrix of ratings is very sparse. IMDB currently inventors around 1,7 millions movies while users rarely rate more than a few hundreds movies. 

In addition to this sparsity constraint, Collaborative Filtering faces several limitations such as the cold-start problem (How to recommend an item that has no rating), scalability issue (Millions of users/products) or lack of external information (how to append side information to help the system). 
A good overview can be found in the [following paper](https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf)

In this post, we will focus on the general case and the network implementation for clarity purpose.

 
## Problem description ##

Matrix of ratings

Create autoencoders that will fill this matrix.
--> picture: 

movieLens




## Sparsity ##
Sparsity big constraint
Picture Autoencoder

Autoencoder ~= dimension reduction


First step : use sparse representation
Torch.sparse
 
Data sparse 
implement parser


## Autoencoder -> Forward ##

Use SparseLinear... Slow
CPU -> use nnsparse.BatchLinear
GPU -> nnsparse.densify() + nn.Linear (Up to 10time faster)

Better implementation undergoing


## Autoencoder -> Loss ##
Unknwon rating??? 
  -> unknown = no error... 
  
  loss = sum (exist)
  
   Backward


## Autoencoder -> Better ##

Yes! Use mask noise
--> loss

Deeper? Yes, harder to train...


## Results ##


## 
This is not deep learning. (look at the title :P)

Another field where the structure of neural networks return excellent restults
Autoencoders were used differently form what they think to do.

This is not naive implementation of neural networks, they are actualy clear motivation why it was likely to work.
The real surprise is : how well they work!









```lua
module = nn.SpatialGlimpse(size, depth, scale)
```


## References
1. *Koren, Y., Bell, R., & Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer, (8), 30-37., 
